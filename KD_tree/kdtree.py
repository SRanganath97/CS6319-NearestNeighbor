# -*- coding: utf-8 -*-
"""KDTree.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16qeluZzHqiUDQXLVKO-daU0AzJZzzUHQ
"""

class KDTree(object):
    def __init__(self, points, dim, dist_sq_func=None):

        if dist_sq_func is None:
            dist_sq_func = lambda a, b: sum((x - b[i]) ** 2 
                for i, x in enumerate(a))
                
        def make(points, i=0):
            if len(points) > 1:
                points.sort(key=lambda x: x[i])
                i = (i + 1) % dim
                m = len(points) >> 1
                return [make(points[:m], i), make(points[m + 1:], i), 
                    points[m]]
            if len(points) == 1:
                return [None, None, points[0]]
        
        def add_point(node, point, i=0):
            if node is not None:
                dx = node[2][i] - point[i]
                for j, c in ((0, dx >= 0), (1, dx < 0)):
                    if c and node[j] is None:
                        node[j] = [None, None, point]
                    elif c:
                        add_point(node[j], point, (i + 1) % dim)

        import heapq
        def get_knn(node, point, k, return_dist_sq, heap, i=0, tiebreaker=1):
            if node is not None:
                dist_sq = dist_sq_func(point, node[2])
                dx = node[2][i] - point[i]
                if len(heap) < k:
                    heapq.heappush(heap, (-dist_sq, tiebreaker, node[2]))
                elif dist_sq < -heap[0][0]:
                    heapq.heappushpop(heap, (-dist_sq, tiebreaker, node[2]))
                i = (i + 1) % dim
                # Goes into the left branch, then the right branch if needed
                for b in (dx < 0, dx >= 0)[:1 + (dx * dx < -heap[0][0])]:
                    get_knn(node[b], point, k, return_dist_sq, 
                        heap, i, (tiebreaker << 1) | b)
            if tiebreaker == 1:
                return [(-h[0], h[2]) if return_dist_sq else h[2] 
                    for h in sorted(heap)][::-1]

        def walk(node):
            if node is not None:
                for j in 0, 1:
                    for x in walk(node[j]):
                        yield x
                yield node[2]

        self._add_point = add_point
        self._get_knn = get_knn 
        self._root = make(points)
        self._walk = walk

    def __iter__(self):
        return self._walk(self._root)
        
    def add_point(self, point):
        if self._root is None:
            self._root = [None, None, point]
        else:
            self._add_point(self._root, point)

    def get_knn(self, point, k, return_dist_sq=True):
        return self._get_knn(self._root, point, k, return_dist_sq, [])

    def get_nearest(self, point, return_dist_sq=True):
        l = self._get_knn(self._root, point, 1, return_dist_sq, [])
        return l[0] if len(l) else None

points = [[1,1,1], [2,2,2], [10,10,10], [1.5,2.5,3.5], [10,10.5,10]]
KD = KDTree(points, 3)
print(KD.get_nearest([1.1,1.1,1.1]))
print(KD.get_knn([1.1,1.1,1.1], 2))

import numpy as np
import pandas as pd
import time
data = pd.read_csv('Iris.csv')
data.head()

points = list(zip(data.SepalLengthCm, data.SepalWidthCm, data.PetalLengthCm, data.PetalWidthCm))
print(points)

from sklearn.model_selection import train_test_split
y = data.Species
X = data.drop(['Species','Id'], axis = 1)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)

points_train = list(zip(X_train.SepalLengthCm, X_train.SepalWidthCm, X_train.PetalLengthCm, X_train.PetalWidthCm))
print(points_train)

KD_train_start_time = time.time()
KD_tree = KDTree(points_train, 4)
KD_train_end_time = time.time()
KD_train_time = KD_train_end_time - KD_train_start_time
print(KD_train_time)

points_test = list(zip(X_test.SepalLengthCm, X_test.SepalWidthCm, X_test.PetalLengthCm, X_test.PetalWidthCm))
print(points_test)

KD_run_start_time = time.time()
kdpoints = []
k = 10
for i in range(len(points_test)):
  p = KD_tree.get_knn(points_test[i], k) #Change K
  #print(p)
  m = []
  for j in range(k):
    m.append(p[j][1])
  kdpoints.append(m)
KD_run_end_time = time.time()
KD_runtime = KD_run_end_time - KD_run_start_time
print(KD_runtime)
#print(kdpoints)

class KNN:
  def __init__(self,k):
    self.k = k
    self.y_predict = []
    
  def find_distances(self,vector_train, vector_test):
    distance = {}
    l = []
    #print("vector_train", vector_train)
    #print("vector_test", vector_test)
    for i in range(len(vector_test)):
      for j in range(len(vector_train)):
        distance[j] = (np.linalg.norm(np.asarray(vector_test[i]) - np.asarray(vector_train[j])))
      points = self.sort(distance)
      l.append(points)
    return (l)

  def sort(self,distance):
    listofTuples = sorted(distance.items() , reverse=False, key=lambda x: x[1])
    return listofTuples[:self.k]

nearest = KNN(k)

KNN_run_start_time = time.time()
predictions = (nearest.find_distances(points_train, points_test))
KNN_run_end_time = time.time()
KNN_runtime = KNN_run_end_time - KNN_run_start_time
print(KNN_runtime)
knn_preds = []
for i in range(len(predictions)):
  n = []
  for j in range(k):
    n.append(points_train[predictions[i][j][0]])
  knn_preds.append(n)
#print(knn_preds)

error = 0
def compare(kdpoints, knn_preds):
  for i in range(len(kdpoints)):
    for j in range(k):
      error += np.linalg.norm(kdpoints[i][j] - knn_preds[i][j])
print(error)

time_difference = KNN_runtime - KD_runtime

time_difference

import random

def generate_vectors(num_vectors, dimensions):
    vectors = []
    
    for i in range(num_vectors):
        vector = [round(random.uniform(0, 100), 1) for _ in range(dimensions)]
        vectors.append(vector)
    
    return vectors

#new_data = generate_vectors(10000, 10)
tot_vec = [5000, 10000, 15000]
dimensions = [5, 10]

def compare(new_kdpoints, new_knn_preds, dim):
  error = 0
  for i in range(len(new_kdpoints)):
    for j in range(dim):
      error += np.linalg.norm(new_kdpoints[i][j] - new_knn_preds[i][j])
  return error
print(error)

KD_train_time = []
KD_runtime = []
KNN_runtime = []
errors = []
for i in range(len(tot_vec)):
  kd = []
  knn = []
  for j in range(len(dimensions)):
    new_data = generate_vectors(tot_vec[i], dimensions[j])
    train_data = new_data[:tot_vec[i] - (tot_vec[i]//3)]
    test_data = new_data[tot_vec[i] - (tot_vec[i]//3):]
    #print(len(train_data), len(test_data))
    KD_train_start_time = time.time()
    KD_tree = KDTree(train_data, dimensions[j])
    KD_train_end_time = time.time()
    KD_train_time.append(KD_train_end_time - KD_train_start_time)
    KD_run_start_time = time.time()
    new_kdpoints = []
    for a in range(len(test_data)):
      p = KD_tree.get_knn(test_data[a], dimensions[j]) #Change K
      #print(p)
      m = []
      for b in range(dimensions[j]):
        m.append(p[b][1])
      new_kdpoints.append(m)
    #print('kd_points',new_kdpoints)
    #print(len(new_kdpoints))
    KD_run_end_time = time.time()
    kd.append(KD_run_end_time - KD_run_start_time)
    print(kd,'kd_time')
    KNN_run_start_time = time.time()
    predictions = (nearest.find_distances(train_data, test_data))
    # print((predictions))
    KNN_run_end_time = time.time()
    knn.append(KNN_run_end_time - KNN_run_start_time)
    print(knn,'KNN_time')
    new_knn_preds = []
    for c in range(len(predictions)):
      n = []
      for d in range(k):
        n.append(train_data[predictions[c][d][0]])
      new_knn_preds.append(n)
    # print(new_knn_preds)
    errors.append(compare(np.array(new_kdpoints), np.array(new_knn_preds), dimensions[j]))
    print(errors)
  KD_runtime.append(kd)
  KNN_runtime.append(knn)
  print(kd, knn)

train_data = new_data[:7001]
test_data = new_data[7001:]
KD_train_start_time = time.time()
KD_tree = KDTree(train_data, 10)
KD_train_end_time = time.time()
KD_train_time = KD_train_end_time - KD_train_start_time
print(KD_train_time)

KD_run_start_time = time.time()
new_kdpoints = []
k = 3
for i in range(len(test_data)):
  p = KD_tree.get_knn(test_data[i], k) #Change K
  #print(p)
  m = []
  for j in range(k):
    m.append(p[j][1])
  new_kdpoints.append(m)
KD_run_end_time = time.time()
new_KD_runtime = KD_run_end_time - KD_run_start_time
print(new_KD_runtime)
#print(new_kdpoints)

KNN_run_start_time = time.time()
predictions = (nearest.find_distances(train_data, test_data))
print((predictions))
KNN_run_end_time = time.time()
new_KNN_runtime = KNN_run_end_time - KNN_run_start_time
print(new_KNN_runtime)
new_knn_preds = []
for i in range(len(predictions)):
  n = []
  for j in range(k):
    n.append(train_data[predictions[i][j][0]])
  new_knn_preds.append(n)
#print(new_knn_preds)

error = 0
def compare(new_kdpoints, new_knn_preds):
  for i in range(len(new_kdpoints)):
    for j in range(k):
      error += np.linalg.norm(new_kdpoints[i][j] - new_knn_preds[i][j])
print(error)

import csv

with open("train_data.csv", "w", newline="") as f:
    writer = csv.writer(f)
    writer.writerows(train_data)

with open("test_data.csv", "w", newline="") as f:
    writer = csv.writer(f)
    writer.writerows(test_data)

knn_times = [KNN_runtime, new_KNN_runtime]
kd_times = [KD_runtime, new_KD_runtime]
time_df = pd.DataFrame(np.array([knn_times, kd_times]), columns=['IRIS', 'random 10k'], index = ['KNN', 'KD_Trees'])
time_df

new_kdpoints = []
k = 1
for i in range(len(test_data)):
  p = KD_tree.get_knn(test_data[i], k) #Change K
  #print(p)
  m = []
  for j in range(k):
    m.append(p[j][1])
  new_kdpoints.append(m)

predictions = (nearest.find_distances(train_data, test_data))
print((predictions))
new_knn_preds = []
for i in range(len(predictions)):
  n = []
  for j in range(k):
    n.append(train_data[predictions[i][j][0]])
  new_knn_preds.append(n)

error = 0
def compare(new_kdpoints, new_knn_preds):
  for i in range(len(new_kdpoints)):
    for j in range(k):
      error += np.linalg.norm(new_kdpoints[i][j] - new_knn_preds[i][j])
print(error)

new_kdpoints = []
k = 5
for i in range(len(test_data)):
  p = KD_tree.get_knn(test_data[i], k) #Change K
  #print(p)
  m = []
  for j in range(k):
    m.append(p[j][1])
  new_kdpoints.append(m)

predictions = (nearest.find_distances(train_data, test_data))
print((predictions))
new_knn_preds = []
for i in range(len(predictions)):
  n = []
  for j in range(k):
    n.append(train_data[predictions[i][j][0]])
  new_knn_preds.append(n)

error = 0
def compare(new_kdpoints, new_knn_preds):
  for i in range(len(new_kdpoints)):
    for j in range(k):
      error += np.linalg.norm(new_kdpoints[i][j] - new_knn_preds[i][j])
print(error)

errors = [0, 0, 0]
error_df = pd.DataFrame(np.array([errors]), columns=['k = 1', 'k = 3', 'k = 5'], index = ['errors'])
error_df

